{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_df shape:  (200000, 202)\n",
      "test_df shape:  (200000, 201)\n",
      "--- 59.55 seconds ---\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import random\n",
    "from sklearn import  metrics\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import  cross_val_score\n",
    "from sklearn.metrics import roc_curve, auc, roc_auc_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import (LinearRegression, Ridge, Lasso, RandomizedLasso, LogisticRegression)\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.feature_selection import RFE\n",
    "import time\n",
    "\n",
    "start_time = time.time()\n",
    "train_df = pd.read_csv('train.csv')\n",
    "test_df = pd.read_csv('test.csv',)\n",
    "submission_df = pd.read_csv('sample_submission.csv')\n",
    "\n",
    "print('train_df shape: ',train_df.shape)\n",
    "print('test_df shape: ',test_df.shape)\n",
    "\n",
    "print(\"--- %s seconds ---\" % round((time.time() - start_time),2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 0.95 seconds ---\n"
     ]
    }
   ],
   "source": [
    "#### ALL ABOUT PREPPING THE TRAIN DATA ####\n",
    "start_time = time.time()\n",
    "\n",
    "\n",
    "target_col = [\"target\"]\n",
    "id_dataset = [\"ID_code\"]\n",
    "#numerical columns\n",
    "num_cols   = [x for x in train_df.columns if x not in target_col + id_dataset]\n",
    "\n",
    "#Scaling Numerical columns\n",
    "#std = StandardScaler()\n",
    "std = MinMaxScaler()\n",
    "scaled = std.fit_transform(train_df[num_cols])\n",
    "scaled = pd.DataFrame(scaled,columns=num_cols)\n",
    "\n",
    "#dropping original values merging scaled values for numerical columns\n",
    "df_data_og = train_df.copy()\n",
    "data = train_df.drop(columns = num_cols,axis = 1)\n",
    "data = data.merge(scaled,left_index=True,right_index=True,how = \"left\")\n",
    "data = data.drop(columns = ['ID_code'],axis = 1)\n",
    "\n",
    "#data['139+81'] = data['var_81'] + data['var_139']\n",
    "#data.drop(['var_81'], axis = 1)\n",
    "#data.drop(['var_139'], axis = 1)\n",
    "\n",
    "print(\"--- %s seconds ---\" % round((time.time() - start_time),2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 1.28 seconds ---\n"
     ]
    }
   ],
   "source": [
    "#### ALL ABOUT PREPPING THE TEST DATA ####\n",
    "start_time = time.time()\n",
    "\n",
    "#test_df['new_col_139+81'] = test_df['var_81'] + test_df['var_139']\n",
    "#test_df.drop(['var_81'], axis = 1)\n",
    "#test_df.drop(['var_139'], axis = 1)\n",
    "\n",
    "target_col = [\"target\"]\n",
    "id_dataset = [\"ID_code\"]\n",
    "#numerical columns\n",
    "num_cols   = [x for x in test_df.columns if x not in target_col + id_dataset]\n",
    "\n",
    "#Scaling Numerical columns\n",
    "#std = StandardScaler()\n",
    "std = MinMaxScaler()\n",
    "scaled = std.fit_transform(test_df[num_cols])\n",
    "scaled = pd.DataFrame(scaled,columns=num_cols)\n",
    "\n",
    "#dropping original values merging scaled values for numerical columns\n",
    "df_test_og = test_df.copy()\n",
    "test = test_df.drop(columns = num_cols,axis = 1)\n",
    "test = test.merge(scaled,left_index=True,right_index=True,how = \"left\")\n",
    "test = test.drop(columns = ['ID_code'],axis = 1)\n",
    "\n",
    "#test['139+81'] = test['var_81'] + test['var_139']\n",
    "#test.drop(['var_81'], axis = 1)\n",
    "#test.drop(['var_139'], axis = 1)\n",
    "\n",
    "\n",
    "print(\"--- %s seconds ---\" % round((time.time() - start_time),2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "var_72     0.013005\n",
      "var_84     0.012363\n",
      "var_68     0.011957\n",
      "var_19     0.011291\n",
      "var_65     0.011214\n",
      "var_143    0.011202\n",
      "var_3      0.011055\n",
      "var_4      0.010915\n",
      "var_120    0.010895\n",
      "var_152    0.010773\n",
      "var_59     0.010448\n",
      "var_189    0.009212\n",
      "var_101    0.009138\n",
      "var_47     0.008983\n",
      "var_42     0.008365\n",
      "var_69     0.008283\n",
      "var_16     0.008117\n",
      "var_37     0.007685\n",
      "var_79     0.007591\n",
      "var_176    0.007469\n",
      "var_61     0.007407\n",
      "var_182    0.007198\n",
      "var_153    0.007103\n",
      "var_73     0.006460\n",
      "var_14     0.006332\n",
      "var_60     0.006265\n",
      "var_129    0.005880\n",
      "var_46     0.005690\n",
      "var_183    0.005467\n",
      "var_160    0.005135\n",
      "var_29     0.004682\n",
      "var_124    0.004218\n",
      "var_161    0.004168\n",
      "var_39     0.004090\n",
      "var_98     0.004074\n",
      "var_158    0.003817\n",
      "var_136    0.003554\n",
      "var_96     0.003037\n",
      "var_7      0.003025\n",
      "var_117    0.002591\n",
      "var_100    0.002215\n",
      "var_10     0.002213\n",
      "var_103    0.001395\n",
      "var_126    0.001393\n",
      "var_41     0.001298\n",
      "var_38     0.000970\n",
      "var_17     0.000864\n",
      "var_30     0.000638\n",
      "var_27     0.000582\n",
      "var_185    0.000053\n",
      "dtype: float64\n",
      "--- 3.52 seconds ---\n"
     ]
    }
   ],
   "source": [
    "#### Check correlation and drop ####\n",
    "start_time = time.time()\n",
    "corr_matrix = pd.DataFrame(data)\n",
    "\n",
    "#corr = corr_matrix.corr().abs()\n",
    "#corr = (corr.where(np.triu(np.ones(corr.shape), k=1).astype(np.bool))\n",
    "#                 .stack()\n",
    "#                 .sort_values(ascending=False))\n",
    "#print(corr.tail(25))\n",
    "\n",
    "#### Also check correlation to target variable ####\n",
    "cor_t = pd.DataFrame(data).apply(lambda x: x.corr(data.target)).abs().sort_values(ascending=False)\n",
    "print(cor_t.tail(50))\n",
    "#corr.to_csv('corr.csv')\n",
    "\n",
    "print(\"--- %s seconds ---\" % round((time.time() - start_time),2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 0.64 seconds ---\n"
     ]
    }
   ],
   "source": [
    "#### Select columns to use ####\n",
    "start_time = time.time()\n",
    "y = data.target\n",
    "x = data.drop(['target'], axis = 1)\n",
    "\n",
    "#for i in range(0,1000): \n",
    "seed = 420\n",
    "x_train, x_test, y_train, y_test= train_test_split(x, y, test_size=0.2, random_state=seed)\n",
    "\n",
    "#from imblearn.over_sampling import SMOTE\n",
    "#smt = SMOTE()\n",
    "#x_train, y_train = smt.fit_sample(x_train, y_train)\n",
    "\n",
    "print(\"--- %s seconds ---\" % round((time.time() - start_time),2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "avg of the cv scores:  0.8592665854851216\n",
      "ROC_AUC is:  0.8619880168851922\n",
      "--- 44.55 seconds ---\n"
     ]
    }
   ],
   "source": [
    "#### Logistic Regression ####\n",
    "start_time = time.time()\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "logreg = LogisticRegression(class_weight='balanced', penalty='l2',\n",
    "                            C=1, solver='liblinear').fit(x_train, y_train)\n",
    "seed = 420\n",
    "kfold = KFold(n_splits=10, random_state=seed)\n",
    "scoring = 'roc_auc'\n",
    "results = cross_val_score(logreg, x_train, y_train,\n",
    "                          cv=kfold, scoring=scoring)\n",
    "print('avg of the cv scores: ',results.mean())\n",
    "\n",
    "prediction = pd.DataFrame(logreg.predict_proba(x_train))\n",
    "prediction = prediction.drop(columns = 0, axis = 1)\n",
    "print('ROC_AUC is: ',roc_auc_score(y_train, prediction))\n",
    "#print(logreg.coef_)\n",
    "\n",
    "#gathering_df = submission_df\n",
    "#gathering_df['logreg']= pd.DataFrame(logreg.predict_proba(test)[:,1])\n",
    "\n",
    "print(\"--- %s seconds ---\" % round((time.time() - start_time),2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Coefficients</th>\n",
       "      <th>Columns</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>1.759204</td>\n",
       "      <td>var_139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>1.627036</td>\n",
       "      <td>var_146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.609851</td>\n",
       "      <td>var_6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>1.594317</td>\n",
       "      <td>var_81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>1.484647</td>\n",
       "      <td>var_110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1.426073</td>\n",
       "      <td>var_12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>1.387969</td>\n",
       "      <td>var_76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1.364923</td>\n",
       "      <td>var_22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>1.337574</td>\n",
       "      <td>var_99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>1.304405</td>\n",
       "      <td>var_53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>1.294511</td>\n",
       "      <td>var_21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>1.294359</td>\n",
       "      <td>var_149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174</th>\n",
       "      <td>1.282952</td>\n",
       "      <td>var_174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190</th>\n",
       "      <td>1.260156</td>\n",
       "      <td>var_190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>1.258635</td>\n",
       "      <td>var_26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192</th>\n",
       "      <td>1.217157</td>\n",
       "      <td>var_192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>1.204275</td>\n",
       "      <td>var_133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165</th>\n",
       "      <td>1.203007</td>\n",
       "      <td>var_165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>1.186709</td>\n",
       "      <td>var_44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179</th>\n",
       "      <td>1.182109</td>\n",
       "      <td>var_179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169</th>\n",
       "      <td>1.180729</td>\n",
       "      <td>var_169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>1.178863</td>\n",
       "      <td>var_148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>1.172169</td>\n",
       "      <td>var_115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>1.159164</td>\n",
       "      <td>var_198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170</th>\n",
       "      <td>1.154312</td>\n",
       "      <td>var_170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166</th>\n",
       "      <td>1.134954</td>\n",
       "      <td>var_166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>1.132301</td>\n",
       "      <td>var_80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>1.129009</td>\n",
       "      <td>var_67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>1.127635</td>\n",
       "      <td>var_34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>184</th>\n",
       "      <td>1.090001</td>\n",
       "      <td>var_184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>0.135625</td>\n",
       "      <td>var_47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>0.135496</td>\n",
       "      <td>var_37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.133963</td>\n",
       "      <td>var_19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>0.130634</td>\n",
       "      <td>var_73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>0.126024</td>\n",
       "      <td>var_117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>0.124521</td>\n",
       "      <td>var_136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>183</th>\n",
       "      <td>0.119815</td>\n",
       "      <td>var_183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189</th>\n",
       "      <td>0.119388</td>\n",
       "      <td>var_189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>0.114871</td>\n",
       "      <td>var_69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>0.099226</td>\n",
       "      <td>var_98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>0.097270</td>\n",
       "      <td>var_41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>0.096101</td>\n",
       "      <td>var_79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.079685</td>\n",
       "      <td>var_7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.078285</td>\n",
       "      <td>var_27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.074981</td>\n",
       "      <td>var_96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.073982</td>\n",
       "      <td>var_16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>0.073053</td>\n",
       "      <td>var_46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>0.072157</td>\n",
       "      <td>var_39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>0.069262</td>\n",
       "      <td>var_38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>0.067507</td>\n",
       "      <td>var_124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>0.061725</td>\n",
       "      <td>var_158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>0.055524</td>\n",
       "      <td>var_160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>0.055334</td>\n",
       "      <td>var_126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>0.049781</td>\n",
       "      <td>var_103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.044839</td>\n",
       "      <td>var_14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>0.037420</td>\n",
       "      <td>var_100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.036388</td>\n",
       "      <td>var_10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.033360</td>\n",
       "      <td>var_17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>185</th>\n",
       "      <td>0.003935</td>\n",
       "      <td>var_185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0.000506</td>\n",
       "      <td>var_30</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>200 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Coefficients  Columns\n",
       "139      1.759204  var_139\n",
       "146      1.627036  var_146\n",
       "6        1.609851    var_6\n",
       "81       1.594317   var_81\n",
       "110      1.484647  var_110\n",
       "12       1.426073   var_12\n",
       "76       1.387969   var_76\n",
       "22       1.364923   var_22\n",
       "99       1.337574   var_99\n",
       "53       1.304405   var_53\n",
       "21       1.294511   var_21\n",
       "149      1.294359  var_149\n",
       "174      1.282952  var_174\n",
       "190      1.260156  var_190\n",
       "26       1.258635   var_26\n",
       "192      1.217157  var_192\n",
       "133      1.204275  var_133\n",
       "165      1.203007  var_165\n",
       "44       1.186709   var_44\n",
       "179      1.182109  var_179\n",
       "169      1.180729  var_169\n",
       "148      1.178863  var_148\n",
       "115      1.172169  var_115\n",
       "198      1.159164  var_198\n",
       "170      1.154312  var_170\n",
       "166      1.134954  var_166\n",
       "80       1.132301   var_80\n",
       "67       1.129009   var_67\n",
       "34       1.127635   var_34\n",
       "184      1.090001  var_184\n",
       "..            ...      ...\n",
       "47       0.135625   var_47\n",
       "37       0.135496   var_37\n",
       "19       0.133963   var_19\n",
       "73       0.130634   var_73\n",
       "117      0.126024  var_117\n",
       "136      0.124521  var_136\n",
       "183      0.119815  var_183\n",
       "189      0.119388  var_189\n",
       "69       0.114871   var_69\n",
       "98       0.099226   var_98\n",
       "41       0.097270   var_41\n",
       "79       0.096101   var_79\n",
       "7        0.079685    var_7\n",
       "27       0.078285   var_27\n",
       "96       0.074981   var_96\n",
       "16       0.073982   var_16\n",
       "46       0.073053   var_46\n",
       "39       0.072157   var_39\n",
       "38       0.069262   var_38\n",
       "124      0.067507  var_124\n",
       "158      0.061725  var_158\n",
       "160      0.055524  var_160\n",
       "126      0.055334  var_126\n",
       "103      0.049781  var_103\n",
       "14       0.044839   var_14\n",
       "100      0.037420  var_100\n",
       "10       0.036388   var_10\n",
       "17       0.033360   var_17\n",
       "185      0.003935  var_185\n",
       "30       0.000506   var_30\n",
       "\n",
       "[200 rows x 2 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parameters = logreg.coef_\n",
    "\n",
    "param_df =pd.DataFrame(parameters).transpose().abs()\n",
    "col_df = pd.DataFrame(x_train.columns)\n",
    "\n",
    "col_df.columns = ['Columns']\n",
    "param_df.columns = ['Coefficients']\n",
    "coef_df = param_df.join(col_df)\n",
    "\n",
    "#coef_df.sort_values('Coefficients')\n",
    "coef_df.sort_values(by='Coefficients',kind=\"quicksort\",ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "avg of the cv scores:  0.8884878927049712\n",
      "ROC_AUC is:  0.8903752339812052\n",
      "--- 11.43 seconds ---\n"
     ]
    }
   ],
   "source": [
    "#### Naive Bayes #### \n",
    "start_time = time.time()\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "NB = GaussianNB().fit(x_train,y_train)\n",
    "seed = 420\n",
    "kfold = KFold(n_splits=10, random_state=seed)\n",
    "scoring = 'roc_auc'\n",
    "results = cross_val_score(NB, x_train, y_train,\n",
    "                          cv=kfold, scoring=scoring)\n",
    "print('avg of the cv scores: ',results.mean())\n",
    "\n",
    "NB_prediction = pd.DataFrame(NB.predict_proba(x_train))\n",
    "NB_prediction = NB_prediction.drop(columns = 0, axis = 1)\n",
    "print('ROC_AUC is: ',roc_auc_score(y_train, NB_prediction))\n",
    "#gathering_df['NB']= pd.DataFrame(NB.predict_proba(test)[:,1])\n",
    "\n",
    "print(\"--- %s seconds ---\" % round((time.time() - start_time),2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.92356728 0.921375   0.9226875  0.917125   0.921625   0.923125\n",
      " 0.917375   0.9220625  0.922625   0.92393275]\n",
      "Accuracy:  0.9215 0.0034\n",
      "AUC:  0.8885 0.0044\n",
      "--- 36.85 seconds ---\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "from sklearn.model_selection import KFold\n",
    "NB_Score = cross_val_score(NB, x_train, y_train, cv = 10)\n",
    "print(NB_Score)\n",
    "\n",
    "from sklearn import model_selection\n",
    "seed = 420\n",
    "kfold = model_selection.KFold(n_splits=10, random_state=seed)\n",
    "model = GaussianNB()\n",
    "scoring = 'accuracy'\n",
    "results = model_selection.cross_val_score(model, x_train, y_train, cv=kfold, scoring=scoring)\n",
    "print('Accuracy: ',round(results.mean(),4), round(results.std(),4))\n",
    "\n",
    "scoring = 'roc_auc'\n",
    "results = model_selection.cross_val_score(model, x_train, y_train, cv=kfold, scoring=scoring)\n",
    "print('AUC: ',round(results.mean(),4), round(results.std(),4))\n",
    "\n",
    "print(\"--- %s seconds ---\" % round((time.time() - start_time),2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.9004 0.0022\n",
      "AUC:  0.6988 0.0071\n",
      "--- 1366.08 seconds ---\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import model_selection\n",
    "\n",
    "seed = 420\n",
    "kfold = model_selection.KFold(n_splits=10, random_state=seed)\n",
    "model = RandomForestClassifier()\n",
    "scoring = 'accuracy'\n",
    "results = model_selection.cross_val_score(model, x_train, y_train, cv=kfold, scoring=scoring)\n",
    "print('Accuracy: ',round(results.mean(),4), round(results.std(),4))\n",
    "\n",
    "scoring = 'roc_auc'\n",
    "results = model_selection.cross_val_score(model, x_train, y_train, cv=kfold, scoring=scoring)\n",
    "print('AUC: ',round(results.mean(),4), round(results.std(),4))\n",
    "\n",
    "print(\"--- %s seconds ---\" % round((time.time() - start_time),2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[35901    40]\n",
      " [ 4003    56]]\n",
      "     1\n",
      "0  0.0\n",
      "1  0.1\n",
      "2  0.1\n",
      "3  0.0\n",
      "4  0.2\n",
      "--- 78.05 seconds ---\n"
     ]
    }
   ],
   "source": [
    "#### Select columns to use ####\n",
    "start_time = time.time()\n",
    "y = data.target\n",
    "x = data.drop(['target'], axis = 1)\n",
    "\n",
    "#for i in range(0,1000): \n",
    "x_train, x_test, y_train, y_test= train_test_split(x, y, test_size=0.2, random_state=seed)\n",
    "\n",
    "model.fit(x_train, y_train)\n",
    "\n",
    "pred = pd.DataFrame(model.predict_proba(x_test))\n",
    "pred = pred.drop(columns = 0, axis = 1)\n",
    "prediction = pred\n",
    "cnf = confusion_matrix(y_test, prediction.round())\n",
    "print(cnf)\n",
    "\n",
    "print(prediction.head())\n",
    "\n",
    "print(\"--- %s seconds ---\" % round((time.time() - start_time),2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Ada Boost Classifer ####\n",
    "#start_time = time.time()\n",
    "#from sklearn.ensemble import AdaBoostClassifier\n",
    "#ABC = AdaBoostClassifier(logreg).fit(x_train,y_train)\n",
    "#ABC_score = cross_val_score(ABC, x_train, y_train, cv=10)\n",
    "#print('avg of the cv scores: ',ABC_score.mean())\n",
    "\n",
    "#ABC_prediction = pd.DataFrame(ABC.predict_proba(x_train))\n",
    "#ABC_prediction = ABC_prediction.drop(columns = 0, axis = 1)\n",
    "#print('ROC_AUC is: ',roc_auc_score(y_train, ABC_prediction))\n",
    "#gathering_df['AdaBoost']= pd.DataFrame(ABC.predict_proba(test)[:,1])\n",
    "\n",
    "#print(\"--- %s seconds ---\" % round((time.time() - start_time),2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ABC' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-13-35b568ddf0f4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#### Output the test results to csv ####\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mstart_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0msubmission_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'target'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mABC\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0msubmission_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'submission_seed.csv'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m#gathering_df.drop(['target'])\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'ABC' is not defined"
     ]
    }
   ],
   "source": [
    "#### Output the test results to csv ####\n",
    "start_time = time.time()\n",
    "submission_df['target']= pd.DataFrame(ABC.predict_proba(test)[:,1])\n",
    "submission_df.to_csv('submission_seed.csv', index=False)\n",
    "#gathering_df.drop(['target'])\n",
    "gathering_df.to_csv('gathering_df.csv',index = False)\n",
    "\n",
    "print(\"--- %s seconds ---\" % round((time.time() - start_time),2))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
