{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 48.45 seconds ---\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import random\n",
    "from sklearn import  metrics\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import  cross_val_score\n",
    "from sklearn.metrics import roc_curve, auc, roc_auc_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import (LinearRegression, Ridge, Lasso, RandomizedLasso, LogisticRegression)\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.feature_selection import RFE\n",
    "import time\n",
    "\n",
    "start_time = time.time()\n",
    "train_df = pd.read_csv('train.csv')\n",
    "test_df = pd.read_csv('test.csv',)\n",
    "submission_df = pd.read_csv('sample_submission.csv')\n",
    "\n",
    "print(\"--- %s seconds ---\" % round((time.time() - start_time),2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 1.54 seconds ---\n"
     ]
    }
   ],
   "source": [
    "#### ALL ABOUT PREPPING THE TRAIN DATA ####\n",
    "\n",
    "start_time = time.time()\n",
    "target_col = [\"target\"]\n",
    "id_dataset = [\"ID_code\"]\n",
    "#numerical columns\n",
    "num_cols   = [x for x in train_df.columns if x not in target_col + id_dataset]\n",
    "\n",
    "#Scaling Numerical columns\n",
    "std = StandardScaler()\n",
    "scaled = std.fit_transform(train_df[num_cols])\n",
    "scaled = pd.DataFrame(scaled,columns=num_cols)\n",
    "\n",
    "#dropping original values merging scaled values for numerical columns\n",
    "df_data_og = train_df.copy()\n",
    "data = train_df.drop(columns = num_cols,axis = 1)\n",
    "data = data.merge(scaled,left_index=True,right_index=True,how = \"left\")\n",
    "data = data.drop(columns = ['ID_code'],axis = 1)\n",
    "\n",
    "print(\"--- %s seconds ---\" % round((time.time() - start_time),2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 1.59 seconds ---\n"
     ]
    }
   ],
   "source": [
    "#### ALL ABOUT PREPPING THE TEST DATA ####\n",
    "start_time = time.time()\n",
    "target_col = [\"target\"]\n",
    "id_dataset = [\"ID_code\"]\n",
    "#numerical columns\n",
    "num_cols   = [x for x in test_df.columns if x not in target_col + id_dataset]\n",
    "\n",
    "#Scaling Numerical columns\n",
    "std = StandardScaler()\n",
    "scaled = std.fit_transform(test_df[num_cols])\n",
    "scaled = pd.DataFrame(scaled,columns=num_cols)\n",
    "\n",
    "#dropping original values merging scaled values for numerical columns\n",
    "df_test_og = test_df.copy()\n",
    "test = test_df.drop(columns = num_cols,axis = 1)\n",
    "test = test.merge(scaled,left_index=True,right_index=True,how = \"left\")\n",
    "test = test.drop(columns = ['ID_code'],axis = 1)\n",
    "\n",
    "print(\"--- %s seconds ---\" % round((time.time() - start_time),2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "target  var_81     0.080917\n",
      "        var_139    0.074080\n",
      "        var_12     0.069489\n",
      "        var_6      0.066731\n",
      "        var_110    0.064275\n",
      "        var_146    0.063644\n",
      "        var_53     0.063399\n",
      "        var_26     0.062422\n",
      "        var_76     0.061917\n",
      "        var_174    0.061669\n",
      "        var_22     0.060558\n",
      "        var_21     0.058483\n",
      "        var_99     0.058367\n",
      "        var_166    0.057773\n",
      "        var_80     0.057609\n",
      "        var_190    0.055973\n",
      "        var_2      0.055870\n",
      "        var_165    0.055734\n",
      "        var_13     0.055156\n",
      "        var_148    0.055011\n",
      "        var_133    0.054548\n",
      "        var_198    0.053000\n",
      "        var_34     0.052692\n",
      "        var_0      0.052390\n",
      "        var_1      0.050343\n",
      "dtype: float64\n",
      "--- 19.51 seconds ---\n"
     ]
    }
   ],
   "source": [
    "#### Check correlation and drop ####\n",
    "start_time = time.time()\n",
    "corr_matrix = pd.DataFrame(data)\n",
    "\n",
    "corr = corr_matrix.corr().abs()\n",
    "corr = (corr.where(np.triu(np.ones(corr.shape), k=1).astype(np.bool))\n",
    "                 .stack()\n",
    "                 .sort_values(ascending=False))\n",
    "print(corr.head(25))\n",
    "\n",
    "#### Also check correlation to target variable ####\n",
    "cor_t = pd.DataFrame(data).apply(lambda x: x.corr(data.target)).abs().sort_values(ascending=False)\n",
    "#print(cor_t.head(5))\n",
    "corr.to_csv('corr.csv')\n",
    "\n",
    "print(\"--- %s seconds ---\" % round((time.time() - start_time),2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 0.58 seconds ---\n"
     ]
    }
   ],
   "source": [
    "#### Select columns to use ####\n",
    "start_time = time.time()\n",
    "y = data.target\n",
    "x = data.drop(['target'], axis = 1)\n",
    "\n",
    "#for i in range(0,1000): \n",
    "seed = 420\n",
    "x_train, x_test, y_train, y_test= train_test_split(x, y, test_size=0.2, random_state=seed)\n",
    "\n",
    "#from imblearn.over_sampling import SMOTE\n",
    "#smt = SMOTE()\n",
    "#x_train, y_train = smt.fit_sample(x_train, y_train)\n",
    "\n",
    "print(\"--- %s seconds ---\" % round((time.time() - start_time),2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "avg of the cv scores:  0.7819875318608888\n",
      "ROC_AUC is:  0.8619911875349053\n",
      "--- 29.74 seconds ---\n"
     ]
    }
   ],
   "source": [
    "#### Logistic Regression ####\n",
    "start_time = time.time()\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "logreg = LogisticRegression(class_weight='balanced', penalty='l2',\n",
    "                            C=1, solver='liblinear').fit(x_train, y_train)\n",
    "\n",
    "model_score = cross_val_score(logreg, x_train, y_train, cv=10, )\n",
    "print('avg of the cv scores: ',model_score.mean())\n",
    "\n",
    "prediction = pd.DataFrame(logreg.predict_proba(x_train))\n",
    "prediction = prediction.drop(columns = 0, axis = 1)\n",
    "print('ROC_AUC is: ',roc_auc_score(y_train, prediction))\n",
    "#print(logreg.coef_)\n",
    "\n",
    "gathering_df = submission_df\n",
    "gathering_df['logreg']= pd.DataFrame(logreg.predict_proba(test)[:,1])\n",
    "\n",
    "print(\"--- %s seconds ---\" % round((time.time() - start_time),2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "avg of the cv scores:  0.9215500022841798\n",
      "ROC_AUC is:  0.8903752339812052\n",
      "--- 12.35 seconds ---\n"
     ]
    }
   ],
   "source": [
    "#### Naive Bayes #### \n",
    "start_time = time.time()\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "NB = GaussianNB().fit(x_train,y_train)\n",
    "NB_score = cross_val_score(NB, x_train, y_train, cv=10,)\n",
    "print('avg of the cv scores: ',NB_score.mean())\n",
    "\n",
    "NB_prediction = pd.DataFrame(NB.predict_proba(x_train))\n",
    "NB_prediction = NB_prediction.drop(columns = 0, axis = 1)\n",
    "print('ROC_AUC is: ',roc_auc_score(y_train, NB_prediction))\n",
    "#gathering_df['NB']= pd.DataFrame(NB.predict_proba(test)[:,1])\n",
    "\n",
    "print(\"--- %s seconds ---\" % round((time.time() - start_time),2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.92356728 0.921375   0.9226875  0.917125   0.921625   0.923125\n",
      " 0.917375   0.9220625  0.922625   0.92393275]\n",
      "Accuracy:  0.9215375 0.003435931460317568\n",
      "AUC:  0.8884878927049712 0.004406832968379841\n",
      "--- 29.1 seconds ---\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "NB_Score = cross_val_score(NB, x_train, y_train, cv = 10)\n",
    "print(NB_score)\n",
    "\n",
    "from sklearn import model_selection\n",
    "seed = 420\n",
    "kfold = model_selection.KFold(n_splits=10, random_state=seed)\n",
    "model = GaussianNB()\n",
    "scoring = 'accuracy'\n",
    "results = model_selection.cross_val_score(model, x_train, y_train, cv=kfold, scoring=scoring)\n",
    "print('Accuracy: ',results.mean(), results.std())\n",
    "\n",
    "scoring = 'roc_auc'\n",
    "results = model_selection.cross_val_score(model, x_train, y_train, cv=kfold, scoring=scoring)\n",
    "print('AUC: ',results.mean(), results.std())\n",
    "\n",
    "print(\"--- %s seconds ---\" % round((time.time() - start_time),2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[35318   623]\n",
      " [ 2562  1497]]\n",
      "          1\n",
      "0  0.013287\n",
      "1  0.010677\n",
      "2  0.061877\n",
      "3  0.003353\n",
      "4  0.852162\n",
      "--- 1.7 seconds ---\n"
     ]
    }
   ],
   "source": [
    "#### Select columns to use ####\n",
    "start_time = time.time()\n",
    "y = data.target\n",
    "x = data.drop(['target'], axis = 1)\n",
    "\n",
    "#for i in range(0,1000): \n",
    "x_train, x_test, y_train, y_test= train_test_split(x, y, test_size=0.2, random_state=seed)\n",
    "\n",
    "model.fit(x_train, y_train)\n",
    "\n",
    "pred = pd.DataFrame(model.predict_proba(x_test))\n",
    "pred = pred.drop(columns = 0, axis = 1)\n",
    "prediction = pred\n",
    "cnf = confusion_matrix(y_test, prediction.round())\n",
    "print(cnf)\n",
    "\n",
    "print(prediction.head())\n",
    "\n",
    "print(\"--- %s seconds ---\" % round((time.time() - start_time),2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "avg of the cv scores:  0.9215875061901366\n",
      "ROC_AUC is:  0.8923248695647825\n",
      "--- 1359.47 seconds ---\n"
     ]
    }
   ],
   "source": [
    "#### Ada Boost Classifer ####\n",
    "start_time = time.time()\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "ABC = AdaBoostClassifier(model).fit(x_train,y_train)\n",
    "ABC_score = cross_val_score(ABC, x_train, y_train, cv=10)\n",
    "print('avg of the cv scores: ',ABC_score.mean())\n",
    "\n",
    "ABC_prediction = pd.DataFrame(ABC.predict_proba(x_train))\n",
    "ABC_prediction = ABC_prediction.drop(columns = 0, axis = 1)\n",
    "print('ROC_AUC is: ',roc_auc_score(y_train, ABC_prediction))\n",
    "gathering_df['AdaBoost']= pd.DataFrame(ABC.predict_proba(test)[:,1])\n",
    "\n",
    "print(\"--- %s seconds ---\" % round((time.time() - start_time),2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 66.55 seconds ---\n"
     ]
    }
   ],
   "source": [
    "#### Output the test results to csv ####\n",
    "start_time = time.time()\n",
    "submission_df['target']= pd.DataFrame(ABC.predict_proba(test)[:,1])\n",
    "submission_df.to_csv('submission_seed.csv', index=False)\n",
    "#gathering_df.drop(['target'])\n",
    "gathering_df.to_csv('gathering_df.csv',index = False)\n",
    "\n",
    "print(\"--- %s seconds ---\" % round((time.time() - start_time),2))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
