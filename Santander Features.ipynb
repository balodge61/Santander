{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 35.8 seconds ---\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import random\n",
    "from sklearn import  metrics\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import  cross_val_score\n",
    "from sklearn.metrics import roc_curve, auc, roc_auc_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import (LinearRegression, Ridge, Lasso, RandomizedLasso, LogisticRegression)\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.feature_selection import RFE\n",
    "import time\n",
    "\n",
    "start_time = time.time()\n",
    "train_df = pd.read_csv('shuffled_half.csv')\n",
    "test_df = pd.read_csv('test.csv',)\n",
    "submission_df = pd.read_csv('sample_submission.csv')\n",
    "\n",
    "print(\"--- %s seconds ---\" % round((time.time() - start_time),1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#shuffled = train_df.sample(frac=1)\n",
    "#shuffled.to_csv('shuffled.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 2.5 seconds ---\n"
     ]
    }
   ],
   "source": [
    "#### Scale the Train and Test Data ####\n",
    "start_time = time.time()\n",
    "target_col = [\"target\"]\n",
    "id_dataset = [\"ID_code\"]\n",
    "#numerical columns\n",
    "num_col_train   = [x for x in train_df.columns if x not in target_col + id_dataset]\n",
    "num_col_test   = [x for x in test_df.columns if x not in target_col + id_dataset]\n",
    "\n",
    "#Scaling Numerical columns\n",
    "std = StandardScaler()\n",
    "scaled = std.fit_transform(train_df[num_col_train])\n",
    "scaled = pd.DataFrame(scaled,columns=num_col_train)\n",
    "\n",
    "#dropping original values merging scaled values for numerical columns\n",
    "df_data_og = train_df.copy()\n",
    "train = train_df.drop(columns = num_col_train,axis = 1)\n",
    "train = train.merge(scaled,left_index=True,right_index=True,how = \"left\")\n",
    "train = train.drop(columns = ['ID_code'],axis = 1)\n",
    "\n",
    "scaled = std.fit_transform(test_df[num_col_test])\n",
    "scaled = pd.DataFrame(scaled,columns=num_col_test)\n",
    "\n",
    "#dropping original values merging scaled values for numerical columns\n",
    "df_test_og = test_df.copy()\n",
    "test = test_df.drop(columns = num_col_test,axis = 1)\n",
    "test = test.merge(scaled,left_index=True,right_index=True,how = \"left\")\n",
    "test = test.drop(columns = ['ID_code'],axis = 1)\n",
    "\n",
    "print(\"--- %s seconds ---\" % round((time.time() - start_time),1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original dataframe shape:  (100000, 202)\n",
      "New dataframe shape::  (100000, 4242)\n",
      "--- 72.1 seconds ---\n"
     ]
    }
   ],
   "source": [
    "#### Lets create features ####\n",
    "start_time = time.time()\n",
    "\n",
    "print('Original dataframe shape: ',train.shape)\n",
    "\n",
    "column = train.columns.tolist()\n",
    "#print(column)\n",
    "test_list_0 = ['var_0','var_1','var_2','var_3','var_4','var_5','var_6','var_7','var_8','var_9',\n",
    "              'var_10','var_11','var_12','var_13','var_14','var_15','var_16','var_17','var_18','var_19']\n",
    "\n",
    "test_list_1 = ['var_20','var_21','var_22','var_23','var_24','var_25','var_26','var_27','var_28','var_29',\n",
    "              'var_30','var_31','var_32','var_33','var_34','var_35','var_36','var_37','var_38','var_39']\n",
    "\n",
    "test_list_2 = ['var_40','var_41','var_42','var_43','var_44','var_45','var_46','var_47','var_48','var_49',\n",
    "              'var_50','var_51','var_52','var_53','var_54','var_55','var_56','var_57','var_58','var_59']\n",
    "\n",
    "test_list_3 = ['var_60','var_61','var_62','var_63','var_64','var_65','var_66','var_67','var_68','var_69',\n",
    "              'var_70','var_71','var_72','var_73','var_74','var_75','var_76','var_77','var_78','var_79']\n",
    "\n",
    "test_list_4 = ['var_80','var_81','var_82','var_83','var_84','var_85','var_86','var_87','var_88','var_89',\n",
    "              'var_90','var_91','var_92','var_93','var_94','var_95','var_96','var_97','var_98','var_99']\n",
    "\n",
    "test_list_5 = ['var_100','var_101','var_102','var_103','var_104','var_105','var_106','var_107','var_108','var_109',\n",
    "              'var_110','var_111','var_112','var_113','var_114','var_115','var_116','var_117','var_118','var_119']\n",
    "\n",
    "test_list_6 = ['var_120','var_121','var_122','var_123','var_124','var_125','var_126','var_127','var_128','var_129',\n",
    "              'var_130','var_131','var_132','var_133','var_134','var_135','var_136','var_137','var_138','var_139']\n",
    "\n",
    "test_list_7 = ['var_140','var_141','var_142','var_143','var_144','var_145','var_146','var_147','var_148','var_149',\n",
    "              'var_150','var_151','var_152','var_153','var_154','var_155','var_156','var_157','var_158','var_159']\n",
    "\n",
    "test_list_8 = ['var_160','var_161','var_162','var_163','var_164','var_165','var_166','var_167','var_168','var_169',\n",
    "              'var_170','var_171','var_172','var_173','var_174','var_175','var_176','var_177','var_178','var_179']\n",
    "\n",
    "test_list_9 = ['var_180','var_181','var_182','var_183','var_184','var_185','var_186','var_187','var_188','var_189',\n",
    "               'var_190','var_191','var_192','var_193','var_194','var_195','var_196','var_197','var_198','var_199']\n",
    "\n",
    "\n",
    "no_target_list = train.drop(columns='target',axis = 1)\n",
    "no_target_list = no_target_list.columns.tolist()\n",
    "\n",
    "for j in test_list_4:\n",
    "    for i in column:\n",
    "        train[j + i] = train[j] / train[i]\n",
    "\n",
    "print('New dataframe shape:: ', train.shape)\n",
    "#print(train.describe())\n",
    "#describe = train.describe()\n",
    "\n",
    "print(\"--- %s seconds ---\" % round((time.time() - start_time),1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "target          1.000000\n",
      "var_81          0.080757\n",
      "var_139         0.076648\n",
      "var_12          0.070510\n",
      "var_26          0.066927\n",
      "var_6           0.066455\n",
      "var_174         0.062355\n",
      "var_146         0.062148\n",
      "var_53          0.062090\n",
      "var_110         0.061352\n",
      "var_76          0.060405\n",
      "var_166         0.060268\n",
      "var_22          0.059852\n",
      "var_99          0.057781\n",
      "var_190         0.057741\n",
      "var_80          0.057542\n",
      "var_21          0.057354\n",
      "var_13          0.056220\n",
      "var_109         0.055796\n",
      "var_81var_68    0.055288\n",
      "var_0           0.055220\n",
      "var_2           0.055068\n",
      "var_133         0.054214\n",
      "var_34          0.054009\n",
      "var_148         0.053721\n",
      "var_165         0.053532\n",
      "var_44          0.053154\n",
      "var_198         0.052954\n",
      "var_40          0.052720\n",
      "var_115         0.050475\n",
      "                  ...   \n",
      "var_35          0.035958\n",
      "var_197         0.035717\n",
      "var_32          0.035652\n",
      "var_180         0.035222\n",
      "var_87          0.034996\n",
      "var_93          0.033934\n",
      "var_71          0.033753\n",
      "var_130         0.033535\n",
      "var_186         0.033424\n",
      "var_157         0.033350\n",
      "var_49          0.033093\n",
      "var_163         0.032855\n",
      "var_131         0.032467\n",
      "var_5           0.032063\n",
      "var_48          0.031743\n",
      "var_188         0.031569\n",
      "var_145         0.031321\n",
      "var_128         0.031138\n",
      "var_94var_68    0.030770\n",
      "var_167         0.030381\n",
      "var_90          0.030243\n",
      "var_141         0.030168\n",
      "var_70          0.029923\n",
      "var_43          0.029769\n",
      "var_111         0.029731\n",
      "var_104         0.029556\n",
      "var_92var_68    0.029413\n",
      "var_125         0.029196\n",
      "var_58          0.029093\n",
      "var_114         0.028648\n",
      "Length: 100, dtype: float64\n",
      "--- 13.6 seconds ---\n"
     ]
    }
   ],
   "source": [
    "#### Check correlation and drop ####\n",
    "start_time = time.time()\n",
    "\n",
    "cor_t = pd.DataFrame(train).apply(lambda x: x.corr(train.target)).abs().sort_values(ascending=False)\n",
    "print(cor_t.head(100))\n",
    "\n",
    "print(\"--- %s seconds ---\" % round((time.time() - start_time),1))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
